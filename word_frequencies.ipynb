{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwrnhb1Q4ooOoo3E9mAyHC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElhamHosseini73/LearnNLP/blob/main/word_frequencies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data\n",
        "import nltk\n",
        "from nltk.corpus import twitter_samples\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "nltk.download('twitter_samples')\n",
        "\n",
        "all_positive_twitt = twitter_samples.strings('positive_tweets.json')\n",
        "all_negetive_twitt = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "all_twitt = all_positive_twitt + all_negetive_twitt\n",
        "\n",
        "lables = np.append(np.ones(len(all_positive_twitt)), np.zeros(len(all_negetive_twitt)))"
      ],
      "metadata": {
        "id": "01gkdgTlHTP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def process_tweet(tweet):\n",
        "    \"\"\"Process tweet function.\n",
        "    Input:\n",
        "        tweet: a string containing a tweet\n",
        "    Output:\n",
        "        tweets_clean: a list of words containing the processed tweet\n",
        "    \"\"\"\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    # remove stock market tickers like $GE\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    # remove old style retweet text \"RT\"\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    # remove hyperlinks\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    # remove hashtags\n",
        "    # only removing the hash # sign from the word\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    # tokenize tweets\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                               reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_english and  # remove stopwords\n",
        "                word not in string.punctuation):  # remove punctuation\n",
        "            # tweets_clean.append(word)\n",
        "            stem_word = stemmer.stem(word)  # stemming word\n",
        "            tweets_clean.append(stem_word)\n",
        "\n",
        "    return tweets_clean"
      ],
      "metadata": {
        "id": "mJE246TsOhSm",
        "outputId": "a30b304a-c8c7-4824-98f2-b5009e448fb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(process_tweet(all_twitt[0]))"
      ],
      "metadata": {
        "id": "MutRRAhm1DVt",
        "outputId": "ab846ab7-88e9-41ef-cced-178636d2dff9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4INfl3ayy5Z"
      },
      "outputs": [],
      "source": [
        "# this function will build a dictionary where we can lookup how many times a word appears in the lists of positive or negative tweets.\n",
        "\n",
        "def build_freqs(tweets, lables):\n",
        "\n",
        "  #   Input: tweets: a list of tweets && lables: an m x 1 array with the sentiment label of each tweet (either 0 or 1)\n",
        "  #   Output: freqs: a dictionary mapping each (word, lable) pair to its frequency\n",
        "\n",
        "\n",
        "\n",
        "  pass"
      ]
    }
  ]
}